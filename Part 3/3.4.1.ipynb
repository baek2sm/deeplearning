{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "3.4.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "880bb53c"
      },
      "source": [
        "# 실습에 필요한 라이브러리를 불러옵니다.\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "id": "880bb53c",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "421de6e7",
        "outputId": "91a2a36d-a465-47d8-c89a-25115864923e"
      },
      "source": [
        "# MNIST DATASET 다운로드\n",
        "!git clone https://github.com/baek2sm/ml.git\n",
        "!tar -zxvf ./ml/datasets/MNIST.tar.gz\n",
        "\n",
        "# 현재 경로에 MNIST 학습 세트와 테스트 세트를 불러옵니다.\n",
        "path = './'\n",
        "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
        "test_dataset = datasets.MNIST(path, train=False, download=True)\n",
        "\n",
        "# 학습 세트와 테스트 세트의 입력 데이터와 타깃을 준비합니다.\n",
        "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
        "X_test, y_test = test_dataset.data / 255, test_dataset.targets"
      ],
      "id": "421de6e7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ml'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 170 (delta 68), reused 148 (delta 51), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (170/170), 62.40 MiB | 27.53 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bcc2e17",
        "outputId": "fac376ac-0848-4bd3-c1cc-a69abc1acd0f"
      },
      "source": [
        "# 학습 세트와 테스트 세트의 데이터 형태를 확인합니다.\n",
        "print('학습 세트 입력 데이터:', X_train.shape)\n",
        "print('학습 세트 타깃:', y_train.shape)\n",
        "print('테스트 세트 입력 데이터:', X_test.shape)\n",
        "print('테스트 세트 타깃:', y_test.shape)"
      ],
      "id": "4bcc2e17",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습 세트 입력 데이터: torch.Size([60000, 28, 28])\n",
            "학습 세트 타깃: torch.Size([60000])\n",
            "테스트 세트 입력 데이터: torch.Size([10000, 28, 28])\n",
            "테스트 세트 타깃: torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faea4b05",
        "outputId": "afaa18f2-7379-4ac2-95f5-573abb3af700"
      },
      "source": [
        "# 2차원(높이, 너비) 형태인 이미지 데이터를 3차원(채널, 높이, 너비) 형태로 변환합니다.\n",
        "X_train, X_test = X_train.unsqueeze(1), X_test.unsqueeze(1)\n",
        "\n",
        "# 학습 세트와 테스트 세트의 데이터 형태를 확인합니다.\n",
        "print('학습 세트 입력 데이터:', X_train.shape)\n",
        "print('테스트 세트 입력 데이터:', X_test.shape)"
      ],
      "id": "faea4b05",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습 세트 입력 데이터: torch.Size([60000, 1, 28, 28])\n",
            "테스트 세트 입력 데이터: torch.Size([10000, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c7b3eaa"
      },
      "source": [
        "# 입력 데이터와 타깃을 묶어 텐서 데이터세트를 생성합니다.\n",
        "train_dset = TensorDataset(X_train, y_train)\n",
        "test_dset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# 한 번에 128개의 데이터 샘플을 배치로 사용하는 데이터로더를 생성합니다.\n",
        "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dset, batch_size=32, shuffle=False)"
      ],
      "id": "6c7b3eaa",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17dfd2dd"
      },
      "source": [
        "# CNN 모델 클래스를 정의합니다.\n",
        "class CNN(nn.Module):\n",
        "    # 생성자에서 모델의 구조를 정의합니다. \n",
        "    def __init__(self):\n",
        "        # 상속받아 생성한 객체이므로 부모(nn.Module)의 생성자를 호출합니다.\n",
        "        super().__init__()\n",
        "        # 첫 번째 은닉층을 정의합니다.\n",
        "        self.hidden_layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=(3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            nn.Dropout(0.5)      \n",
        "        )        \n",
        "        # 두 번째 은닉층을 정의합니다.\n",
        "        self.hidden_layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),      \n",
        "            nn.Dropout(0.5)      \n",
        "        )\n",
        "        # 세 번째 은닉층을 정의합니다.\n",
        "        self.hidden_layer3 = nn.Linear(128*5*5, 128)\n",
        "        # 출력층을 정의합니다.\n",
        "        self.output_layer = nn.Linear(128, 10)        \n",
        "    # 모델의 순전파를 정의합니다.\n",
        "    def forward(self, X):\n",
        "        # 생성자에서 만든 은닉층과 출력층 노드로 타깃을 추론하고 반환합니다.\n",
        "        out = self.hidden_layer1(X)\n",
        "        out = self.hidden_layer2(out)                        \n",
        "        out = out.view(out.shape[0], -1)  # 전결합층을 사용하기 위해 1차원 배열 형태로 변환합니다.        \n",
        "        out = self.hidden_layer3(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out"
      ],
      "id": "17dfd2dd",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0de05d87"
      },
      "source": [
        "# 그래픽카드 사용이 가능할 경우 그래픽카드로 연산하도록 설정합니다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 합성곱 신경망 모델 객체를 생성합니다.\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 크로스 엔트로피(Cross Entropy) 손실 함수 객체를 생성합니다.\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# 확률적 경사 하강법 옵티마이저 객체를 생성합니다.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "id": "0de05d87",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fd0f229"
      },
      "source": [
        "# 학습 함수를 정의합니다.\n",
        "def train(model, criterion, optimizer, loader):\n",
        "  # 현재 에포크의 오차와 정확도를 저장할 변수를 생성합니다.\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  # 모델을 학습 모드로 설정합니다.\n",
        "  model.train()\n",
        "\n",
        "  # 배치 학습을 실행합니다.\n",
        "  for X_batch, y_batch in loader:\n",
        "    # 입력 데이터와 타깃의 배치를 그래픽 카드로 연산하도록 설정합니다.\n",
        "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "    # 기울기를 초기화합니다.\n",
        "    optimizer.zero_grad()\n",
        "    # 모델을 사용해 타깃을 추론합니다.\n",
        "    hypothesis = model(X_batch)\n",
        "    # 손실 함수로 오차를 계산합니다.\n",
        "    loss = criterion(hypothesis, y_batch)        \n",
        "    # 기울기를 계산합니다.\n",
        "    loss.backward()\n",
        "    # 경사 하강법으로 가중치를 수정합니다.\n",
        "    optimizer.step()\n",
        "    # 정확도를 계산합니다.\n",
        "    y_predicted = torch.argmax(hypothesis, 1)\n",
        "    acc = (y_predicted == y_batch).float().mean()\n",
        "    # 현재 배치의 오차와 정확도를 저장합니다.\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  # 현재 에포크의 오차와 정확도를 반환합니다.\n",
        "  return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "id": "5fd0f229",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c3c1c26"
      },
      "source": [
        "# 평가 함수를 정의합니다.\n",
        "def evaluate(model, criterion, optimizer, loader):\n",
        "  # 현재 에포크의 오차와 정확도를 저장할 변수를 생성합니다.\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  # 모델을 평가 모드로 설정합니다.\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # 배치 단위로 추론을학습을 실행합니다.\n",
        "    for X_batch, y_batch in loader:\n",
        "      # 입력 데이터와 타깃의 배치를 그래픽 카드로 연산하도록 설정합니다.\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      # 모델을 사용해 타깃을 추론합니다.\n",
        "      hypothesis = model(X_batch)\n",
        "      # 손실 함수로 오차를 계산합니다.\n",
        "      loss = criterion(hypothesis, y_batch)\n",
        "      # 정확도를 계산합니다.\n",
        "      y_predicted = torch.argmax(hypothesis, 1)\n",
        "      acc = (y_predicted == y_batch).float().mean()\n",
        "      # 현재 배치의 오차와 정확도를 저장합니다.\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "    # 현재 에포크의 오차와 정확도를 반환합니다.\n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "id": "4c3c1c26",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1f506a9",
        "outputId": "24868051-f9db-4931-a367-d8c69af4fe62"
      },
      "source": [
        "# 20에 걸쳐 모델을 학습시킵니다.\n",
        "n_epochs = 20\n",
        "for epoch in range(1, n_epochs+1):\n",
        "  # 모델을 학습시킵니다.\n",
        "  loss, acc = train(model, criterion, optimizer, train_loader)\n",
        "\n",
        "  # 모델을 평가합니다.\n",
        "  test_loss, test_acc = evaluate(model, criterion, optimizer, test_loader)\n",
        "\n",
        "  # 현재 에포크의 학습 결과를 출력합니다.\n",
        "  print('epoch: {}, loss: {:.3f}, acc: {:.2f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(\n",
        "       epoch, loss, acc, test_loss, test_acc))\n"
      ],
      "id": "c1f506a9",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, loss: 0.418, acc: 0.88, test_loss: 0.121, test_acc: 0.967\n",
            "epoch: 2, loss: 0.143, acc: 0.96, test_loss: 0.077, test_acc: 0.977\n",
            "epoch: 3, loss: 0.104, acc: 0.97, test_loss: 0.062, test_acc: 0.981\n",
            "epoch: 4, loss: 0.089, acc: 0.97, test_loss: 0.048, test_acc: 0.985\n",
            "epoch: 5, loss: 0.080, acc: 0.98, test_loss: 0.043, test_acc: 0.987\n",
            "epoch: 6, loss: 0.071, acc: 0.98, test_loss: 0.040, test_acc: 0.988\n",
            "epoch: 7, loss: 0.065, acc: 0.98, test_loss: 0.036, test_acc: 0.988\n",
            "epoch: 8, loss: 0.060, acc: 0.98, test_loss: 0.034, test_acc: 0.989\n",
            "epoch: 9, loss: 0.057, acc: 0.98, test_loss: 0.035, test_acc: 0.989\n",
            "epoch: 10, loss: 0.055, acc: 0.98, test_loss: 0.032, test_acc: 0.990\n",
            "epoch: 11, loss: 0.052, acc: 0.98, test_loss: 0.031, test_acc: 0.990\n",
            "epoch: 12, loss: 0.048, acc: 0.98, test_loss: 0.029, test_acc: 0.990\n",
            "epoch: 13, loss: 0.045, acc: 0.99, test_loss: 0.029, test_acc: 0.990\n",
            "epoch: 14, loss: 0.045, acc: 0.99, test_loss: 0.026, test_acc: 0.991\n",
            "epoch: 15, loss: 0.043, acc: 0.99, test_loss: 0.026, test_acc: 0.991\n",
            "epoch: 16, loss: 0.040, acc: 0.99, test_loss: 0.026, test_acc: 0.992\n",
            "epoch: 17, loss: 0.040, acc: 0.99, test_loss: 0.025, test_acc: 0.992\n",
            "epoch: 18, loss: 0.038, acc: 0.99, test_loss: 0.026, test_acc: 0.992\n",
            "epoch: 19, loss: 0.038, acc: 0.99, test_loss: 0.025, test_acc: 0.992\n",
            "epoch: 20, loss: 0.035, acc: 0.99, test_loss: 0.024, test_acc: 0.991\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}