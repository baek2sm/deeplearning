{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"3.5.3 LSTM 실습.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5NLyDSHmDAr2OH7yCdVM0"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQR0C6UEG1Pf"},"source":["# 실습에 필요한 라이브러리를 불러옵니다.\r\n","from torchtext import data, datasets\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmbn-5sHHEOh"},"source":["# 텍스트 데이터 처리 방법을 정의합니다.\r\n","sentence_length = 500\r\n","TEXT = data.Field(batch_first=True, lower=True, fix_length=sentence_length)\r\n","LABEL = data.LabelField(batch_first=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zE78_95gIFcE","executionInfo":{"status":"ok","timestamp":1615122925967,"user_tz":-540,"elapsed":30738,"user":{"displayName":"홍승백","photoUrl":"","userId":"17288301376861649879"}},"outputId":"0d445a17-c192-4ed6-844f-f6bef94c028e"},"source":["# IMDB 데이터 세트를 학습 세트와 테스트 세트로 나눠 불러옵니다.\r\n","train_datasets, test_datasets = datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["downloading aclImdb_v1.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 21.6MB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLNdS0eg6GEL","executionInfo":{"status":"ok","timestamp":1615124630327,"user_tz":-540,"elapsed":595,"user":{"displayName":"홍승백","photoUrl":"","userId":"17288301376861649879"}},"outputId":"bdd0fe7f-ca1b-47cb-d958-8f378d11ec37"},"source":["# 학습 데이터의 첫 번째 데이터 샘플을 출력해봅니다.\r\n","print(vars(train_datasets[20000])['label'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["neg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1ckdrY9J7fv","executionInfo":{"status":"ok","timestamp":1615122940249,"user_tz":-540,"elapsed":2057,"user":{"displayName":"홍승백","photoUrl":"","userId":"17288301376861649879"}},"outputId":"a954a3f0-d5df-4784-8ac6-a18a39711414"},"source":["# 단어 집합을 정의합니다.\r\n","TEXT.build_vocab(train_datasets, max_size=10000)\r\n","LABEL.build_vocab(train_datasets)\r\n","\r\n","# 단어 집합의 길이를 확인합니다.\r\n","print('number of total words: {}'.format(len(TEXT.vocab)))\r\n","print('number of total classes: {}'.format(len(LABEL.vocab)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["number of total words: 10002\n","number of total classes: 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zr2hzx1mK4G7"},"source":["# 데이터 이터레이터를 준비합니다.\r\n","train_iterator, test_iterator = data.BucketIterator.splits(\r\n","        (train_datasets, test_datasets),\r\n","        batch_size=32,\r\n","        device='cuda'\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOJoO93kjXKt"},"source":["# LSTM 모델 클래스를 정의합니다.\r\n","class LSTM(nn.Module):\r\n","  def __init__(self, vocab_size, sentence_length):\r\n","    super().__init__()\r\n","    # 문장의 길이를 저장합니다.\r\n","    self.sentence_length = sentence_length\r\n","    # 모델 구조를 정의합니다.\r\n","    self.embed = nn.Embedding(vocab_size, 16)\r\n","    self.cell = nn.LSTM(16, 16, batch_first=True)\r\n","    self.fc = nn.Linear(self.sentence_length * 16, 1)\r\n","    self.sigmoid = nn.Sigmoid()\r\n"," \r\n","  # 순전파를 정의합니다.\r\n","  def forward(self, X):\r\n","    out = self.embed(X)\r\n","    out, hidden_state = self.cell(out)\r\n","    out = out.contiguous()\r\n","    out = self.fc(out.view(-1, self.sentence_length * 16))\r\n","    out = self.sigmoid(out)\r\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMkwXgY1lUXl"},"source":["# LSTM 모델 객체를 생성합니다.\r\n","vocab_size = len(TEXT.vocab)\r\n","model = LSTM(vocab_size, sentence_length).to('cuda')\r\n","\r\n","# 이진 크로스 엔트로피(Binary Cross Entropy Error) 손실 함수 객체를 생성합니다.\r\n","criterion = nn.BCELoss().to('cuda')\r\n","\r\n","# 아담 옵티마이저 객체를 생성합니다.\r\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kfzf_HslGa8R"},"source":["# 학습 함수를 정의합니다.\r\n","def train(model, criterion, optimizer, iterator):\r\n","  # 현재 에포크의 오차와 정확도를 저장할 변수를 생성합니다.\r\n","  epoch_loss = 0\r\n","  epoch_acc = 0\r\n","\r\n","  # 모델을 학습 모드로 설정합니다.\r\n","  model.train()\r\n","\r\n","  # 배치 학습을 실행합니다.\r\n","  for batch in iterator:\r\n","    # 입력 데이터와 타깃을 준비합니다.\r\n","    X_batch, y_batch = batch.text, batch.label.float().view(-1, 1)\r\n","    # 기울기를 초기화합니다.\r\n","    optimizer.zero_grad()\r\n","    # 모델을 사용해 타깃을 예측합니다.\r\n","    hypothesis = model(X_batch)\r\n","    # 손실 함수로 오차를 계산합니다.\r\n","    loss = criterion(hypothesis, y_batch)        \r\n","    # 기울기를 계산합니다.\r\n","    loss.backward()\r\n","    # 경사 하강법으로 가중치를 수정합니다.\r\n","    optimizer.step()\r\n","    # 정확도를 계산합니다.\r\n","    acc = ((hypothesis >= 0.5) == y_batch).float().mean()\r\n","    # 현재 배치의 오차와 정확도를 저장합니다.\r\n","    epoch_loss += loss.item()\r\n","    epoch_acc += acc.item()\r\n","\r\n","  # 현재 에포크의 오차와 정확도를 반환합니다.\r\n","  return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C94z4efYK2KD"},"source":["# 테스트 함수를 정의합니다.\r\n","def evaluate(model, criterion, optimizer, iterator):\r\n","  # 현재 에포크의 오차와 정확도를 저장할 변수를 생성합니다.\r\n","  epoch_loss = 0\r\n","  epoch_acc = 0\r\n","\r\n","  # 모델을 평가 모드로 설정합니다.\r\n","  model.eval()\r\n","\r\n","  with torch.no_grad():\r\n","    # 배치 학습을 실행합니다.\r\n","    for batch in iterator:\r\n","      # 입력 데이터와 타깃을 준비합니다.\r\n","      X_batch, y_batch = batch.text, batch.label.float().view(-1, 1)\r\n","      # 모델을 사용해 타깃을 예측합니다.\r\n","      hypothesis = model(X_batch)\r\n","      # 손실 함수로 오차를 계산합니다.\r\n","      loss = criterion(hypothesis, y_batch)\r\n","      # 정확도를 계산합니다.\r\n","      acc = ((hypothesis >= 0.5) == y_batch).float().mean()\r\n","      # 현재 배치의 오차와 정확도를 저장합니다.\r\n","      epoch_loss += loss.item()\r\n","      epoch_acc += acc.item()\r\n","\r\n","    # 현재 에포크의 오차와 정확도를 반환합니다.\r\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvqVEySFwjyg","executionInfo":{"status":"ok","timestamp":1615123164965,"user_tz":-540,"elapsed":197528,"user":{"displayName":"홍승백","photoUrl":"","userId":"17288301376861649879"}},"outputId":"b6eec14c-07b6-4a9e-edb2-6711f7c459ef"},"source":["# 10회에 걸쳐 모델을 학습합니다.\r\n","n_epoch = 10\r\n","for epoch in range(n_epoch):\r\n","  # 모델을 학습시킵니다.\r\n","  loss, acc = train(model, criterion, optimizer, train_iterator)\r\n","\r\n","  # 모델을 평가합니다.\r\n","  test_loss, test_acc = evaluate(model, criterion, optimizer, test_iterator)\r\n","\r\n","  # 현재 에포크의 학습 결과를 출력합니다.\r\n","  print('epoch: {}, loss: {:.3f}, acc: {:.2f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(\r\n","      epoch+1, loss, acc, test_loss, test_acc\r\n","  )) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1, loss: 0.637, acc: 0.61, test_loss: 0.542, test_acc: 0.728\n","epoch: 2, loss: 0.437, acc: 0.80, test_loss: 0.475, test_acc: 0.781\n","epoch: 3, loss: 0.325, acc: 0.86, test_loss: 0.407, test_acc: 0.821\n","epoch: 4, loss: 0.255, acc: 0.90, test_loss: 0.396, test_acc: 0.835\n","epoch: 5, loss: 0.203, acc: 0.92, test_loss: 0.400, test_acc: 0.838\n","epoch: 6, loss: 0.160, acc: 0.94, test_loss: 0.429, test_acc: 0.843\n","epoch: 7, loss: 0.128, acc: 0.95, test_loss: 0.450, test_acc: 0.844\n","epoch: 8, loss: 0.100, acc: 0.97, test_loss: 0.498, test_acc: 0.843\n","epoch: 9, loss: 0.073, acc: 0.98, test_loss: 0.579, test_acc: 0.842\n","epoch: 10, loss: 0.053, acc: 0.98, test_loss: 0.625, test_acc: 0.840\n"],"name":"stdout"}]}]}